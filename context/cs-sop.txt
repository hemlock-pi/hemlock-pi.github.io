I am interested in theoretical and empirical machine learning, with a focus on how modern generative models learn from structured data and how collections of models can be coordinated into coherent systems. On the theoretical side, I study how assumptions on data and training objectives shape what generative models can learn efficiently. On the empirical side, I have worked on representation geometry and routing policies for SWE agents. In graduate school, I hope to work on problems at the intersection of machine learning foundations and the design of intelligent systems, particularly questions about data geometry in generative models, learning dynamics and stability in agentic systems, and how tools from economics might inform multi-agent system design.
Research Experience
Theoretical ML (MAGICS Lab)
My theoretical work comprises three projects on diffusion and flow-matching transformers; I discuss the two most important ones here. In the first, I co-authored a NeurIPS paper studying diffusion transformers under the manifold hypothesis. A central question in deep generative modeling is how sample complexity scales with dimension. The manifold hypothesis offers a way out: if data concentrate near a lower-dimensional structure, complexity might scale with intrinsic rather than ambient dimension. We showed that diffusion transformers can exploit this structure and derived minimax-optimal sample complexity bounds with explicit dependence on intrinsic dimension. 
In the second project, I led a first-author investigation of flow-matching transformers that makes this latent-manifold perspective more precise. Flow matching is closely related to diffusion, but instead of reversing a stochastic process, it directly learns a deterministic velocity field from Gaussian noise to the data distribution. Since our NeurIPS paper justified latent diffusion architectures via manifold structure, it was natural to ask whether flow matching could benefit from an analogous decomposition, but the right object to decompose was not obvious. After weeks of mapping out the geometry of conditional flows, I realized the velocity field itself was the right object.
I proved a velocity decomposition theorem: under a linear latent subspace assumption, the optimal velocity splits into tangent and orthogonal components that can be learned separately. This yields an identifiability result (on-manifold dynamics are uniquely determined by data) and built-in stability (the orthogonal component is contractive).  
Although this was sufficient to answer our initial question, I felt that there was geometric insight that we hadn’t fully appreciated. After trying to distill the identifiability result to its core, I arrived at a geometric picture that drew an analogy between axis-aligned loss landscapes and our decoupleable risk function. From this analogy it was suddenly clear what our decomposition offered: the guarantee that unilaterally optimizing along the tangent or orthogonal components would result in an update onto a (weakly) better level set of loss (without our decomposition, it would be possible to update onto a worse level set). Architecturally, this motivated a two-headed transformer with a high-capacity tangent head and a lightweight orthogonal head. We also derived intrinsic-dimension-optimal minimax rates. This project is complete and we plan to submit to ICML.
Empirical ML and Agentic Systems
I have also worked on a few applied/empirical ML systems. My most significant project is my internship at CMU's Language Technologies Institute with Prof. Graham Neubig working on software-engineering agents. I fine tuned a small Qwen model to act as a learned router over multiple language models with different cost-performance tradeoffs, framing the problem as learning a value function over partial SWE trajectories. The RL framework was intentionally simple, yet we observed clear gains over single-LLM baselines. More interesting was how the individual models were unaware they were part of a team, but the router mediated implicit collaboration where a pool of specialized models collectively outperformed any single model. This raises questions about why multi-agent setups can outperform single agents and how theory-guided models of collaboration could help us design such systems. This is ongoing work targeting either TACL or ICML. 
Network Economics
For my senior thesis (advised by Prof. Ben Golub) in Northwestern's interdisciplinary MMSS program, I am studying how structural balance and external information jointly affect polarization in signed network models. In control theory and distributed systems, there is a family of models, often called gossip protocols or consensus dynamics, that describe how agents iteratively update beliefs based on their neighbors' opinions. The classical literature, following DeGroot, assumes agents update by averaging over neighbors, treating all influence as cooperative. This framework is well-understood: under mild connectivity assumptions, agents converge to consensus, and the mathematics reduces to spectral analysis of row-stochastic matrices. But both Bayesian learning agents and natural social phenomena involve antagonistic relationships, where agents may oppose or repel from certain neighbors. A small recent literature has introduced signed graphs with "opposing" and "repelling" update rules, but existing analyses rely on restrictive assumptions: structural balance (no "enemy of my enemy is my enemy" triangles), absolute row-stochasticity, and constant external signals. The informationless case is reasonably well understood, but the only analysis of the informational regime requires a four-way conjunction of these assumptions. My thesis asks what happens outside this restrictive case: what is the long-run behavior under time-varying external information with repelling dynamics? What breaks when we relax structural balance? So far, I have corrected spurious claims in the literature and generalized key lemmas relating structural balance to spectral properties. My goal is to characterize long-run behavior across these unexplored regimes.
Outlook
MIT EECS has an unusual concentration of faculty whose work sits at the intersection of machine learning, game theory, and social systems, precisely where I want to build my research. I am particularly interested in how Bailey Flanigan's work on sortition algorithms and smoothed analysis of social choice asks how mathematical structure constrains what is achievable in democratic processes. Working on my thesis on signed networks (which operates in a similar space) and coursework in social choice and data economics has created a foundation that I would be excited to build upon in my PhD. Stephen Bates’s work on building statistical tools for settings where strategic agents affect the distribution of observed data resonates with my thesis work on how external information interacts with network updating rules, and I would be excited about doing further research in this direction. Manish Raghavan's work on network formation and algorithmic fairness also dovetails with my interests in working toward making theoretical advances translate into systems that serve human interests.
Both Bailey Flanigan and Manish Raghavan were recommended to me by Keyon Vafa, a Harvard postdoc whose work on internal world models for LLMs I discussed with him after his talk at a CMU workshop this summer.
Ultimately my goal is to become a research professor; I hope to pursue a PhD so that I can research the questions I care about - how to design learning systems that are theoretically well-understood, computationally powerful, and aligned with collective human interests. I find real joy in sharing ideas and learning from others, and I want a career that makes that exchange central.

